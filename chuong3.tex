\setcounter{chapter}{2}
\chapter{MỘT SỐ ỨNG DỤNG CỦA PCA}
\indent Chương này trình bày một số ứng dụng của PCA. Ứng dụng đầu tiên của PCA chính là việc giảm chiều dữ liệu, giúp
việc lưu trữ và tính toán được thuận tiện hơn. Thực tế cho thấy, nhiều khi làm
việc trên dữ liệu đã được giảm chiều mang lại kết quả tốt hơn so với dữ liệu
gốc. Thứ nhất, có thể phần dữ liệu mang thông tin nhỏ bị lược đi chính là phần
gây nhiễu, những thông tin quan trọng hơn đã được giữ lại. Thứ hai, số điểm dữ
liệu nhiều khi ít hơn số chiều dữ liệu. Khi có quá ít dữ liệu và số chiều dữ
liệu quá lớn, quá khớp rất dễ xảy ra. Việc giảm chiều dữ liệu phần nào giúp
khắc phục hiện tượng này. Nội dung chương này tham khảo một số tài liệu \cite{4}, \cite{5}, cite{6}.
\section{Khuôn mặt riêng}
Nhận dạng mặt người (Face recognition) là một lĩnh vực nghiên cứu của ngành Computer Vision, và cũng được xem là một lĩnh vực nghiên cứu của ngành Biometrics (tương tự như nhận dạng vân tay – Fingerprint recognition, hay nhận dạng mống mắt – Iris recognition). Xét về nguyên tắc chung, nhận dạng mặt có sự tương đồng rất lớn với nhận dạng vân tay và nhận dạng mống mắt, tuy nhiên sự khác biệt nằm ở bước trích chọn đặt trưng (feature extraction) của mỗi lĩnh vực. Trong khi nhận dạng vân tay và mống mắt đã đạt tới độ chín, tức là có thể áp dụng trên thực tế một cách rộng rãi thì nhận dạng mặt người vẫn còn nhiều thách thức và vẫn là một lĩnh vực nghiên cứu thú vị với nhiều người. So với nhận dạng vân tay và mống mắt, nhận dạng mặt có nguồn dữ liệu phong phú hơn (bạn có thể nhìn thấy mặt người ở bất cứ tấm ảnh, video clip nào liên quan tới con người trên mạng) và ít đòi hỏi sự tương tác có kiểm soát hơn (để thực hiện nhận dạng vân tay hay mống mắt, dữ liệu input lấy từ con người đòi hỏi có sự hợp tác trong môi trường có kiểm soát). Hiện nay các phương pháp nhận dạng mặt được chia thành nhiều hướng theo các tiêu chí khác nhau: nhận dạng với dữ liệu đầu vào là ảnh tĩnh 2D(still image based FR) là phổ biến nhất, tuy nhiên tương lai có lẽ sẽ là 3D FR (vì việc bố trí nhiều camera 2D sẽ cho dữ liệu 3D và đem lại kết quả tốt hơn, đáng tin cậy hơn), cũng có thể chia thành 2 hướng là: làm với dữ liệu ảnh và làm với dữ liệu video. Trên thực tế người ta hay chia các phương pháp nhận dạng mặt ra làm 3 loại: phương pháp tiếp cận toàn cục (global, như Eigenfaces-PCA, Fisherfaces-LDA), phương pháp tiếp cận dựa trên các đặc điểm cục bộ (local feature based, như LBP, Gabor wavelets) và phương pháp lai (hybrid, là sự kết hợp của hai phương pháp toàn cục và local feature). Phương pháp dựa trên các đặc điểm cục bộ đã được chứng minh là ưu việt hơn khi làm việc trong các điều kiện không có kiểm soát và có thể nói rằng lịch sử phát triển của nhận dạng mặt (A never ending story) là sự phát triển của các phương pháp trích chọn đặc trưng (feature extractrion methods) được sử dụng trong các hệ thống dựa trên feature based. Các ứng dụng cụ thể của nhận dạng mặt dựa trên 2 mô hình nhận dạng: identification (xác định danh tính, bài toán 1-N), và verification (xác thực danh tính, bài toán 1-1). Trong bài toán identification, ta cần xác định danh tính của ảnh kiểm tra, còn trong bài toán verification ta cần xác định 2 ảnh có cùng thuộc về một người hay không.

Các pha trong một hệ thống nhận dạng mặt: để xây dựng một hệ thống nhận dạng mặt, cũng không hề đơn giản, bước đầu tiên cần thực hiện là face detection, tức là phát hiện phần ảnh mặt trong dữ liệu input (CSDL ảnh, video …) và cắt lấy phần ảnh mặt để thực hiện nhận dạng (face cropping), bước thứ hai là tiền xử lý ảnh (preprocessing) bao gồm các bước căn chỉnh ảnh (face image alignment) và chuẩn hóa ánh sáng (illumination normalization) (ở đây tôi đang nói tới các ảnh có góc nhìn thẳng – frontal view face image), tiếp đến là bước trích chọn đặc điểm (feature extraction), ở bước này một phương pháp trích chọn đặc điểm nào đó (mẫu nhị phân cục bộ – Local Binary Pattern – LBP, Gabor wavelets, …) sẽ được sử dụng với ảnh mặt để trích xuất các thông tin đặc trưng cho ảnh, kết quả là mỗi ảnh sẽ được biểu diễn dưới dạng một vector đặc điểm (feature vector), bước tiếp theo là bước nhận dạng (recognition) hay phân lớp (classification), tức là xác định danh tính (identity) hay nhãn (label) của ảnh – đó là ảnh của ai. Ở bước classification, thường thì phương pháp k-láng giềng gần nhất (k-nearest neighbor:kNN) sẽ được sử dụng, thực tế cho thấy việc dùng SVM (Support Vector Machine) không mang lại hiệu quả cao hơn mà còn chậm hơn. Dữ liệu cho một hệ thống nhận dạng mặt được chia làm 3 tập: tập huấn luyện (training set), tập tham chiếu (reference set hay gallery set) và tập để nhận dạng (probe set hay query set, đôi khi còn gọi là test set). Trong nhiều hệ thống, tập training trùng với tập reference. Tập training gồm các ảnh được dùng để huấn luyện (hay học-learning), thông thường tập này được dùng để sinh ra một không gian con (projection subspace) là một ma trận và phương pháp hay được sử dụng là PCA (Principal Component Analysis), WPCA (Whitened PCA), LDA (Linear Discriminant Analysis), KPCA (Kernel PCA). Tập reference gồm các ảnh đã biết danh tính được chiếu (projected) vào không gian con ở bước training. Bước training nhằm 2 mục đích: giảm số chiều (dimension reduction) của các vector đặc điểm (feature vector) vì các vector này thường có độ dài khá lớn (vài nghìn tới vài trăm nghìn) nên nếu để nguyên thì việc tính toán sẽ rất rất lâu, thứ hai là làm tăng tính phân biệt (discriminative) giữa các ảnh khác lớp (định danh khác nhau), ngoài ra có thể làm giảm tính phân biệt giữa các ảnh thuộc về một lớp (tùy theo phương pháp, ví dụ như Linear Discriminant Analysis LDA- còn gọi là Fisher Linear Discriminant Analysis-Fisherface là một phương pháp làm việc với tập training mà mỗi đối tượng có nhiều ảnh mặt ở các điều kiện khác nhau). Sau khi thực hiện chiếu tập reference vào không gian con, hệ thống lưu lại kết quả là một ma trận với mỗi cột của ma trận là một vector tương ứng với ảnh (định danh đã biết) để thực hiện nhận dạng (hay phân lớp). Nhận dạng (hay phân lớp) được thực hiện với tập các ảnh probe, sau khi tiền xử lý xong, mỗi ảnh sẽ được áp dụng phương pháp trích chọn đặc điểm (như với các ảnh thuộc tập training và reference) và được chiếu vào không gian con. Tiếp đến việc phân lớp sẽ dựa trên phương pháp k-NN, định danh của một ảnh cần xác định sẽ được gán là định danh của ảnh có khoảng cách (distance) gần với nó nhất. Ở đây cần lưu ý là mỗi ảnh là một vector nên có thể dùng khái niệm hàm khoảng cách giữa hai vector để đo sự khác biệt giữa các ảnh.

Các thách thức đối với nhận dạng mặt: hiện nay các vấn đề sau được coi là thách thức lớn (chưa có phương pháp tốt) đối với nhận dạng mặt:

+ vấn đề hướng (pose variations), các kết quả với các ảnh có hướng thay đổi (>45 độ, không phải chính diện) còn khá khiêm tốn, có lẽ 3D là một hướng giải quyết.

+ vấn đề ảnh có độ phân giải thấp (low resolution): ảnh thu được từ các camera giám sát (surveillance camera) thường có kích thước và chất lượng rất rất thấp, các kết quả nghiên cứu về lĩnh vực này còn chưa nhiều.

+ làm việc với dữ liêu video (video based face recognition): với sự phát triển của các phương tiện multimedia, thông tin mặt người trong các dữ liệu video là vô cùng nhiều, tuy nhiên hầu hết các phương pháp nhận dạng vẫn làm việc với ảnh tĩnh trích xuất từ dữ liệu video, chưa có phương pháp tốt tận dụng hết ưu thế của dữ liệu video.

+ các hệ thống cực lớn (very large scale systems): các cơ sở dữ liệu (CSDL) ảnh mặt được test bởi các nhà nghiên cứu còn khá nhỏ (vài trăm tới vài chục nghìn ảnh mặt), tuy nhiên trên thực tế các CSDL có thể rất lớn, ví dụ CSDL ảnh mặt của cảnh sát của một nước có thể chứa từ hàng triệu tới hơn 1 tỉ ảnh …

+ aging condition: việc nhận dạng ảnh mặt thay đổi theo thời gian thực sự vẫn còn là một vấn đề lớn ngay cả đối với khả năng nhận dạng của con người.

+ illumination (ánh sáng): là một trong những biggest challenges của nhận dạng mặt, chưa có phương pháp tốt cho các ảnh chụp ở điều kiện out door unconstrained.

Nguồn gốc của các thách thức trên là do tập training thường chỉ có một ảnh cho mỗi đối tượng (lớp) với các điều kiện cố định, trong khi tập probe lại gồm các ảnh ở các điều kiện khác (như đã liệt kê ở trên), làm gia tăng sự khác biệt giữa ảnh training, gallery và probe.

Nghiên cứu về nhận dạng mặt: vì có nhiều bước và còn nhiều thách thức nên có thể lựa chọn một khía cạnh trong một bước để tiến hành, ví dụ như chỉ nghiên cứu về illumination normalization, hay chỉ làm với ảnh low resolution, nhận dạng cảm xúc của khuôn mặt, hoặc thậm chí cụ thể hơn nữa, chỉ làm về face image alignment … Tuy nhiên hầu hết các nhà nghiên cứu đều tập trung vào bước feature extraction, tức là tìm một cách thức trích chọn đặc điểm hiệu quả cho nhận dạng mặt.

\index{khuôn mặt riêng -- eigenface}
\index{eigenface -- khuôn mặt riêng}
\textit{Khuôn mặt riêng} (eigenface) từng là một trong những kỹ thuật phổ biến
trong bài toán nhận dạng khuôn mặt. Ý tưởng của khuôn mặt riêng là đi tìm một
không gian có số chiều nhỏ hơn để mô tả mỗi khuôn mặt, từ đó sử dụng vector
trong không gian thấp chiều này như vector đặc trưng cho bộ phân loại. Điều đáng
nói là một bức ảnh khuôn mặt có kích thước khoảng 200 $\times$ 200 sẽ có số
chiều là 40k -- một số rất lớn, trong khi đó, vector đặc trưng thường chỉ có số
chiều bằng vài trăm hoặc vài nghìn. Khuôn mặt riêng thực ra chính là PCA. Các
khuôn mặt riêng chính là các vector riêng ứng với những trị riêng lớn nhất của
ma trận hiệp phương sai.

\index{cơ sở dữ liệu khuôn mặt Yale -- Yale face database}
\index{Yale face database -- cơ sở dữ liệu khuôn mặt Yale}
Trong phần này, ta sử dụng \textit{cơ sở dữ liệu
	khuôn mặt Yale}. Các bức ảnh đã được căn chỉnh cho cùng với kích thước và khuôn mặt nằm trọn vẹn trong
một hình chữ nhật có kích thước $116 \times  98$ điểm ảnh. Có tất cả 15 người khác
nhau, mỗi người có 11 bức ảnh được chụp ở các điều kiện ánh sáng và cảm xúc khác
nhau, bao gồm \textbf{'centerlight', 'glasses', 'happy', 'leftlight',
	'noglasses', 'normal', 'rightlight','sad', 'sleepy', 'surprised'}, và
\textbf{'wink'}. Hình \ref{fig:28_1} minh hoạ các bức ảnh của
người có id là 10.
% <hr>
% <div class="imgcap">
% <img src ="/assets/28_pca2/yaleb_exs.png" align = "center" width = "800">
% </div>

% <div class = "thecap" align = "left">Hình 1: Ví dụ về ảnh của một người trong Yale Face Database. </div>
% <hr>

\begin{figure}[t]
	\centering
	\includegraphics[width = \textwidth]{Chapters/07_DimemsionalityReduction/28_pca2/latex/yaleb_exs.pdf}
	\caption{Ví dụ về ảnh của một người trong Yale Face Database.}
	\label{fig:28_1}
\end{figure}
Ta thấy rằng số chiều dữ liệu $116 \times 98 = 11368$ là một số khá
lớn. Tuy nhiên, vì chỉ có tổng cộng $15 \times 11 = 165$ bức ảnh nên ta có thể
nén các bức ảnh này về dữ liệu mới có chiều nhỏ hơn 165. Trong ví dụ này, chúng
ta chọn $K = 100$.

Dưới đây là đoạn code thực hiện PCA cho toàn bộ dữ liệu. Một số hàm trong \textbf{sklearn} được sử dụng:
\newpage
\begin{lstlisting}[language=Python]
import numpy as np
from scipy import misc                     # for loading image
np.random.seed(1)

# filename structure
path = 'unpadded/' # path to the database
ids = range(1, 16) # 15 persons
states = ['centerlight', 'glasses', 'happy', 'leftlight',
'noglasses', 'normal', 'rightlight','sad',
'sleepy', 'surprised', 'wink' ]
prefix = 'subject'
surfix = '.pgm'
# data dimension
h, w, K = 116, 98, 100 # hight, weight, new dim
D = h * w
N = len(states)*15
# collect all data
X = np.zeros((D, N))
cnt = 0
for person_id in range(1, 16):
for state in states:
fn = path + prefix + str(person_id).zfill(2) + '.' + state + surfix
X[:, cnt] = misc.imread(fn).reshape(D)
cnt += 1

# Doing PCA, note that each row is a datapoint
from sklearn.decomposition import PCA
pca = PCA(n_components=K) # K = 100
pca.fit(X.T)
# projection matrix
U = pca.components_.T
\end{lstlisting}


Trong dòng \textbf{pca = PCA(n components=K)}, nếu
\textbf{n components} là một số thực trong khoảng $(0, 1)$, PCA sẽ thực
hiện việc tìm $K$ dựa trên biểu thức~\eqref{eqn:28_6}.

% ******************************************************************************
\begin{figure}[t]
	\centering
	\includegraphics[width = \textwidth]{Chapters/07_DimemsionalityReduction/28_pca2/latex/yaleb_eig.pdf}
	\caption{Các eigenfaces tìm được bằng PCA.}
	\label{fig:28_2}
\end{figure}
% ******************************************************************************

Hình \ref{fig:28_2} biểu diễn 18 vector riêng đầu tiên (18 cột đầu tiên của $\bU_k$) tìm được bằng PCA. Các vector đã được \textbf{reshape} về cùng
kích thước như các bức ảnh gốc. Nhận thấy các
vector thu được ít nhiều mang thông tin của mặt người. Thực tế, một khuôn mặt
gốc sẽ được xấp xỉ như tổng có trọng số của các {khuôn mặt} này. Vì các
vector riêng này đóng vai trò như cơ sở của không gian mới với ít chiều hơn,
chúng còn được gọi là \textit{khuôn mặt riêng} hoặc \textit{khuôn mặt chính}. Từ \textit{chính} được dùng vì nó đi kèm với văn cảnh
của \textit{phân tích thành phần chính}.
% ******************************************************************************
\begin{figure}[t]
	\centering
	\includegraphics[width = \textwidth]{Chapters/07_DimemsionalityReduction/28_pca2/latex/yaleb_ori_res.pdf}
	\caption{Hàng trên: các ảnh gốc. Hàng dưới: các ảnh được tái tạo dùng khuôn mặt riêng. Ảnh ở hàng dưới có nhiễu nhưng vẫn mang những đặc điểm riêng mà mắt người có thể phân biệt được.}
	\label{fig:28_3}
\end{figure}
% ******************************************************************************

Để xem mức độ hiệu quả của phương pháp này, chúng ta  minh hoạ các bức ảnh gốc và các bức ảnh được xấp xỉ bằng PCA như trên
Hình~\ref{fig:28_3}. Các khuôn mặt nhận được vẫn mang khá đầy đủ thông tin của
các khuôn mặt gốc. Đáng chú ý hơn, các khuôn mặt trong hàng dưới được suy ra
từ một vector 100 chiều, so với 11368 chiều như ở hàng trên.
\section{Dò tìm điểm bất thường}
Ngoài các ứng dụng về nén và phân loại, PCA còn được sử dụng trong nhiều lĩnh
vực khác. \textit{Dò tìm điểm bất thường} (abnormal detection hoặc {outlier
	detection}) là một trong số đó. 

Ý tưởng cơ bản là giả sử tồn tại một không gian con mà các sự kiện bình thường
nằm gần trong khi các sự kiện bất thường nằm xa không gian con đó. Hơn nữa, số
sự kiện bất thường có một tỉ lệ nhỏ. Như vậy, PCA có thể được sử dụng trên toàn
bộ dữ liệu để tìm ra các thành phần chính, từ đó suy ra không gian con mà các điểm bình thường nằm gần.
Việc xác định một điểm là bình thường hay bất thường được xác định bằng cách đo
khoảng cách từ điểm đó tới không gian con tìm được. Hình~\ref{fig:28_4} minh hoạ
cho việc xác định các sự kiện bất thường bằng PCA. Giả sử các sự kiện {bình thường} chiếm đa số và nằm gần  một không
gian con nào đó. Khi đó, nếu làm PCA trên toàn bộ dữ liệu, không gian con thu được gần với không gian con của tập các sự kiện {bình thường}. Lúc này, các điểm hình tròn to đậm hơn có thể được coi là các sự kiện {bất thường} vì chúng nằm xa không gian con chính.

\begin{figure}[ht]
	\centering
			\includegraphics[width=.75\textwidth]{Chapters/07_DimemsionalityReduction/28_pca2/latex/abnormal.pdf}
	\caption{ PCA cho bài toán dò tìm điểm bất thường.}
		\label{fig:28_4}
	 % figure here


\end{figure}
\section{Ứng dụng PCA trong tài chính}
PCA được sử dụng nhiều trong kinh doanh và học thuật. Phương pháp này (thường được ghép nối với các mô hình học máy khác) đã giúp các nhà khoa học dữ liệu đạt được kết quả ấn tượng trong các nhiệm vụ dự đoán chuỗi thời gian, nén dữ liệu và trực quan hóa dữ liệu.

Trong tài chính, nó thường được sử dụng để phân tích rủi ro tài chính, khám phá và chiến lược giao dịch năng động, chênh lệch giá thống kê và dự đoán giá cổ phiếu tài chính.

Nói chung, dự đoán giá cổ phiếu dựa trên giả định rằng các mô hình thị trường lặp lại theo thời gian và giá cả luôn gắn liền với một số biến kinh tế vĩ mô và các biến cơ bản như tỷ lệ sổ sách trên thị trường và lợi suất thu nhập, có thể được kiểm tra cho các mục đích dự đoán.

Cũng có một nhóm nghiên cứu quan trọng cho thấy các dự đoán giá có thể được tạo từ dữ liệu giá trên lợi nhuận lịch sử và nghiên cứu cụ thể này giới thiệu một phương pháp dự đoán chung mạnh mẽ cho các giá trị giá cổ phiếu dựa trên thông tin hiệp phương sai.

Thông thường, các chuyên gia học máy sử dụng các công cụ ước tính khả năng xảy ra tối đa thông thường để ước lượng ma trận hiệp phương sai hoặc trong một số trường hợp cụ thể là hiệp phương sai thực nghiệm. Tuy nhiên, cả hai phương pháp này đều thất bại trong các tình huống mà số chiều của ma trận là rất lớn so với số lượng biến.

Để khắc phục điều này, nhiều công cụ ước tính giảm chiều đã được đề xuất, ví dụ như PCA - có thể đảo ngược và được điều hòa tốt (đảo ngược nó không dẫn đến khuếch đại lỗi). Phương pháp này sử dụng PCA để dự báo giá cổ phiếu và theo nhiều cách tương tự như kỹ thuật lọc không gian con sử dụng sự phân hủy trực giao của không gian dữ liệu nhiễu thành không gian con nhiễu và tín hiệu.

\textbf{Eigen Portfolio cho thị trường chứng khoán Việt Nam}

Ví dụ về PCA để lấy danh mục đầu tư chính cho thị trường chứng khoán Việt Nam. 
a lưu mã chứng khoán theo cột, còn dòng hiển thị giá chứng khoán theo ngày, tất cả dữ liệu VN30 từ ngày 01/01/2019-01/01/2020 được lưu trong biến: data

Ta tính lợi nhuận của các cổ phiếu (ma trận ret)

for i=2:size(data,1)

% ret(i,:)=log((data(i,:))./data(i-1,:));

ret(i,:)=(data(i,:)-data(i-1,:))./data(i-1,:);

end

Chuẩn hóa dữ liệu (sao cho trung bình bằng 0, và phương sai 1)

X=zscore(ret);

Tính ma các vecto riêng và trị riêng của ma trận hiệp phương sai và hiển thị khả năng giải thích phương sai của 3 thành phần chính)

[COEFF,SCORE,latent] = princomp(X);

percent=cumsum(latent)./sum(latent);

percent(1:3)

Ta sẽ tạo một portfolio từ vecto riêng thứ I (giải thích được nhiều phương sai nhất, trong trường hợp này là khoảng 43%), ta còn gọi đây là Eigen Portfolio (màu xanh), và so sánh với đường VN30-index(màu đỏ)

w=COEFF(:,1)./(sum(COEFF(:,1)));

COEFF(:,1): là vecto riêng ứng với trị riêng lớn nhất

w: là vecto chứa tỷ lệ tài sản đầu tư vào từng loại chứng khoán

pof=data*w;

hold on

Và cuối cùng ta chuẩn hóa Eigen Portfolio và Vn30-index để so sánh

plot(zscore(pof),’b’)

plot(zscore(prices(:,775)),’r’)
Ta thấy là Eigen Portfolio thể hiện khá chính xác dáng điệu của đường VN30-index, mà ở đây ta hoàn toàn không sử dụng đến số lượng cổ phiếu lưu hành
\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{vn30}
	\caption{Danh mục đầu tư chính sử dụng PCA.}
	\label{fig:vn30}
\end{figure}
\section{Ứng dụng PCA trong trực quan hóa dữ liệu, khử nhiễu}
\subsection{Giảm chiều và trực quan hóa dữ liệu}
Để hiểu về dữ liệu hơn, chúng ta mong muốn trực quan hóa dữ liệu. Tính hữu ích của việc giảm chiều dữ liệu có thể không hoàn toàn rõ ràng chỉ trong hai chiều, nhưng trở nên rõ ràng hơn nhiều khi nhìn vào dữ liệu có số chiều lớn. Để thấy điều này, chúng ta hãy xem ứng dụng của PCA đối với dữ liệu chữ số viết tay trong bộ cơ sở dữ liệu MNIST.
\begin{lstlisting}[language=Python]
from sklearn.datasets import load_digits
digits = load_digits()
digits.data.shape 
\end{lstlisting}
Ban đầu dữ liệu bao gồm các hình ảnh $8\time 8$ pixel, nghĩa là chúng là các điểm dữ liệu 64 chiều. Để có một số trực quan về mối quan hệ giữa những điểm này, chúng ta có thể sử dụng PCA để chiếu chúng tới một số chiều dễ quản lý hơn, chẳng hạn như
\begin{lstlisting}[language=Python]
pca = PCA(2)  # project from 64 to 2 dimensions
projected = pca.fit_transform(digits.data)
print(digits.data.shape)
print(projected.shape)
\end{lstlisting}
Và nhận được 

(1797, 64)

(1797, 2)

Bây giờ chúng ta có thể vẽ biểu đồ hai thành phần chính đầu tiên của mỗi điểm để tìm hiểu về dữ liệu.
\begin{lstlisting}[language=Python]
plt.scatter(projected[:, 0], projected[:, 1],
c=digits.target, edgecolor='none', alpha=0.5,
cmap=plt.cm.get_cmap('spectral', 10))
plt.xlabel('component 1')
plt.ylabel('component 2')
plt.colorbar();
\end{lstlisting}
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.9\linewidth]{Trucquandl}
	\caption{Trực quan dữ liệu sử dụng 2 thành phần chính trong PCA.}
	\label{fig:trucquandl}
\end{figure}
Nhắc lại ý nghĩa của các thành phần này: dữ liệu đầy đủ là đám mây điểm $64$ chiều và các điểm này là hình chiếu của mỗi điểm dữ liệu dọc theo các hướng có phương sai lớn nhất. Về cơ bản, chúng ta đã tìm thấy độ giãn và xoay tối ưu trong không gian 64 chiều cho phép chúng ta nhìn thấy bố cục của các chữ số theo hai chiều và đã thực hiện điều này theo phương thức học không giám sát, nghĩa là không cần tham chiếu đến các nhãn.

Chúng ta có thể đi xa hơn một chút ở đây và làm rõ xem các chiều giảm có nghĩa gì. Ý nghĩa này có thể được hiểu theo cách kết hợp của các vectơ cơ sở. Ví dụ: mỗi hình ảnh trong tập huấn luyện được xác định bởi một tập hợp các giá trị $64$ pixel, chúng ta sẽ gọi là vectơ $\bf{x}$:
$$x = x_1, x_2, x_3 \cdots x_{64}$$
Một cách chúng ta có thể nghĩ về điều này là dựa trên cơ sở pixel. Nghĩa là, để xây dựng hình ảnh, chúng ta nhân từng phần tử của vectơ với pixel mà nó mô tả, sau đó cộng các kết quả lại với nhau để xây dựng hình ảnh:
$${\rm image}(x) = x_1 \cdot{\rm (pixel~1)} + x_2 \cdot{\rm (pixel~2)} + x_3 \cdot{\rm (pixel~3)} \cdots x_{64} \cdot{\rm (pixel~64)}$$
Một cách chúng ta có thể tưởng tượng khi giảm chiều của dữ liệu này là loại bỏ tất cả trừ một vài trong số các vectơ cơ sở này. Ví dụ: nếu chúng ta chỉ sử dụng $8$ pixel đầu tiên, chúng ta sẽ có được hình chiếu $8$ chiều của dữ liệu, nhưng nó không phản chiếu toàn bộ hình ảnh: chúng ta đã loại bỏ gần 90\% số pixel!
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.7\linewidth]{hinhcopy3}
	\caption{Dữ liệu biểu diễn theo 8 chiều chính.}
	\label{fig:hinhcopy3}
\end{figure}
Hàng trên của bảng hiển thị các pixel riêng lẻ và hàng dưới cho thấy đóng góp tích lũy của các pixel này vào việc xây dựng hình ảnh. Chỉ sử dụng tám trong số các thành phần dựa trên pixel, chúng ta chỉ có thể tạo một phần nhỏ của hình ảnh 64 pixel. Nếu chúng ta tiếp tục trình tự này và sử dụng tất cả 64 pixel, chúng ta sẽ khôi phục hình ảnh ban đầu.

Nhưng cách biểu diễn theo pixel không phải là sự lựa chọn cơ sở duy nhất. Chúng ta cũng có thể sử dụng các hàm cơ bản khác, mỗi hàm chứa một số đóng góp được xác định trước từ mỗi pixel và viết như sau
$$image(x) = {\rm mean} + x_1 \cdot{\rm (basis~1)} + x_2 \cdot{\rm (basis~2)} + x_3 \cdot{\rm (basis~3)} \cdots$$
PCA có thể được coi là một quá trình lựa chọn các hàm cơ sở tối ưu, sao cho chỉ thêm một vài hàm đầu tiên của chúng lại với nhau là đủ để cấu trúc lại một cách thích hợp phần lớn các phần tử trong tập dữ liệu. Các thành phần chính, đóng vai trò là biểu diễn chiều thấp của dữ liệu, chỉ đơn giản là các hệ số nhân từng phần tử trong chuỗi này. Hình này cho thấy mô tả tương tự về việc tái tạo lại chữ số này bằng cách sử dụng giá trị trung bình cộng với tám hàm cơ sở PCA đầu tiên:

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.7\linewidth]{Hinhcopy4}
	\caption{Tái tạo lại chữ số bằng 8 cơ sở PCA đầu tiên.}
	\label{fig:hinhcopy4}
\end{figure}
Không giống như cơ sở pixel, cơ sở PCA cho phép chúng ta khôi phục các tính năng nổi bật của hình ảnh đầu vào chỉ với một trung bình cộng với tám thành phần! Số lượng mỗi pixel trong mỗi thành phần là hệ quả của hướng của vectơ trong ví dụ hai chiều của chúng ta. Đây là ý nghĩa mà PCA cung cấp một biểu diễn dữ liệu theo chiều thấp: nó phát hiện ra một tập hợp các hàm cơ sở hiệu quả hơn so với cơ sở pixel gốc của dữ liệu đầu vào.

Một phần quan trọng của việc sử dụng PCA trong thực tế là khả năng ước tính có bao nhiêu thành phần cần thiết để mô tả dữ liệu. Điều này có thể được xác định bằng cách xem xét tỷ lệ phương sai được giải thích tích lũy như là một hàm của số thành phần
\begin{lstlisting}[language=Python]
pca = PCA().fit(digits.data)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');
\end{lstlisting}
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.7\linewidth]{hinhcopy5}
	\caption{Tương quan giữa số thành phần chính giữ lại và Phương sai.}
	\label{fig:hinhcopy5}
\end{figure}
Đường cong này định lượng bao nhiêu trong tổng phương sai $64$ chiều được chứa trong $N$ thành phần đầu tiên. Ví dụ: chúng ta thấy rằng với các chữ số viết tay trong MNIST, $10$ thành phần đầu tiên chứa khoảng 75\% phương sai, trong khi ta chỉ cần khoảng $50$ thành phần để mô tả gần 100\% phương sai.

Ở đây, chúng ta thấy rằng phép chiếu hai chiều của chúng ta mất rất nhiều thông tin (như được đo bằng phương sai được giải thích) và chúng ta cần khoảng 20 thành phần để giữ lại 90\% phương sai. Nhìn vào biểu đồ này để biết số chiều lớn có thể giúp ta hiểu mức độ dư thừa hiện tại trong nhiều lần quan sát.
\subsection{Khử nhiễu dùng PCA}
PCA cũng có thể được sử dụng như một phương pháp lọc dữ liệu nhiễu. Ý tưởng là: bất kỳ thành phần nào có phương sai lớn hơn nhiều so với ảnh hưởng của nhiễu sẽ tương đối không bị ảnh hưởng bởi nhiễu. Vì vậy, nếu ta xây dựng lại dữ liệu chỉ bằng cách sử dụng tập hợp con lớn nhất của các thành phần chính, ta nên ưu tiên giữ tín hiệu và loại bỏ nhiễu.

Hãy xem điều này trông như thế nào với dữ liệu các chữ số MNIST. Đầu tiên, chúng ta sẽ vẽ một số dữ liệu đầu vào không có nhiễu
\begin{lstlisting}[language=Python]
def plot_digits(data):
fig, axes = plt.subplots(4, 10, figsize=(10, 4),
subplot_kw={'xticks':[], 'yticks':[]},
gridspec_kw=dict(hspace=0.1, wspace=0.1))
for i, ax in enumerate(axes.flat):
ax.imshow(data[i].reshape(8, 8),
cmap='binary', interpolation='nearest',
clim=(0, 16))
plot_digits(digits.data)
\end{lstlisting}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.7\linewidth]{hinhcopy6}
	\caption{Dữ liệu chưa có nhiễu.}
	\label{fig:hinhcopy6}
\end{figure}
Bây giờ, ta thêm một số nhiễu ngẫu nhiên để tạo một tập dữ liệu nhiễu và vẽ lại nó
\begin{lstlisting}[language=Python]
np.random.seed(42)
noisy = np.random.normal(digits.data, 4)
plot_digits(noisy)
\end{lstlisting}
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.8\linewidth]{hinhcopy7}
	\caption{Dữ liệu đã cộng nhiễu}
	\label{fig:hinhcopy7}
\end{figure}
Bằng mắt thường, hình ảnh bị nhiễu và chứa các pixel giả sẽ thấy rõ. Chúng ta sẽ huấn luyện PCA về dữ liệu nhiễu, yêu cầu phép chiếu bảo toàn 50\% phương sai:
\begin{lstlisting}[language=Python]
pca = PCA(0.50).fit(noisy)
pca.n_components_
\end{lstlisting}
12

Ở đây 50\% phương sai tương đương với $12$ thành phần chính. Bây giờ chúng ta tính toán các thành phần này và sau đó sử dụng phép nghịch đảo của phép biến đổi để tạo lại các chữ số đã lọc:
\begin{lstlisting}[language=Python]
components = pca.transform(noisy)
filtered = pca.inverse_transform(components)
plot_digits(filtered)
\end{lstlisting}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.8\linewidth]{hinhcopy8}
	\caption{Dữ liệu sau khi giảm chiều PCA, đã chống được nhiễu.}
	\label{fig:hinhcopy8}
\end{figure}
Thuộc tính bảo toàn tín hiệu, lọc nhiễu này làm cho PCA trở thành một quy trình lựa chọn thuộc tính rất hữu ích — ví dụ: thay vì huấn luyện bộ phân loại trên dữ liệu có chiều rất cao, thay vào đó ta có thể đào tạo bộ phân loại trên biểu diễn chiều thấp hơn, điều này sẽ tự động phân loại để lọc ra nhiễu ngẫu nhiên trong các đầu vào.